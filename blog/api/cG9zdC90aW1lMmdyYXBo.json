{"title":"Time2Graph","date":"2019-11-21T10:30:00.000Z","slug":"time2graph","comments":true,"tags":["科研"],"categories":["技术"],"updated":"2020-01-30T02:28:06.000Z","content":"<h1 id=\"模型：时序到图\">模型：时序到图<a href=\"post/time2graph#模型：时序到图\"></a></h1><h4 id=\"Time2Graph-Revisting-Time-Series-Modeling-with-Dynamic-Shapelets\">Time2Graph: Revisting Time Series Modeling with Dynamic Shapelets<a href=\"post/time2graph#Time2Graph-Revisting-Time-Series-Modeling-with-Dynamic-Shapelets\"></a></h4><p>今年双十一收到了AAAI录用的消息，我们研究已久的一个工作，Time2Graph，终于被录用了。该工作通过shapelet（具有代表性的时序子序列）将时序数据转化为网络进行表示，从而更好地捕捉观测数据的动态演化模式并提升下游应用的可解释性。同时，该工作还与国家电网合作，应用于计量异常检测。下面将对我们这项工作作跟详细的介绍。</p>\n<h4 id=\"时间序列建模\">时间序列建模<a href=\"post/time2graph#时间序列建模\"></a></h4><p>时间序列建模旨在发现数据中的时间关系，学术界对其有广泛研究，例如图像对齐<sup>[2]</sup>，语音识别<sup>[3]</sup>等。这里的关键问题是如何提取时间序列中代表性的特征。以前的工作很大一部分从经典的特征工程和表示学习入手，到最近基于深度学习的模型。尽管这些方法取得了良好的性能<sup>[4,5]</sup>，但由于缺乏可解释性，因此也受到了批评。</p>\n<h4 id=\"动机：动态的Shapelet\">动机：动态的Shapelet<a href=\"post/time2graph#动机：动态的Shapelet\"></a></h4><p><strong>Shapelet</strong>: 代表一类可以在分类场景中提供直接的解释性和见解的时间序列子序列<sup>[6]</sup>，并且基于shapelet的模型在各种研究中都被证明是有前景的<sup>[7,8,9]</sup>。 现有的工作主要静态的分析shapelet。但是，在现实世界中，shapelet通常是动态的，这体现在两个方面： </p>\n<ul>\n<li>首先，出现在不同时间段的同一个shapelet可能会产生不同的影响。例如，在检测到窃电用户的场景下，夏季或冬季的低电耗比春季更可疑，因为制冷或供暖设备的使用使得用电量应该更高。 </li>\n<li>其次，确定shapelet的演化方式对于全面理解时间序列至关重要。实际上，在特定时间具有较小值的shapelet很难将窃电用户与确实消耗少量电的普通用户区分开。一种替代方法是识别曾经具有高电耗的shapelet，但突然消耗很少的用户。换句话说，这里的一个重要线索是shapelet如何随时间演变。 </li>\n</ul>\n<p>我们将能够反映其在不同时间片上的代表性的时间序列子序列称为具有时间意识的shapelet (time-aware shapelet)。此外，为了深入挖掘shapelet的动态性和相关性，我们提出了一种新颖的方法，通过提取具有时间感知的shapelet并构建shapelet演化图来学习时间序列的表示，可以参考我们AAAI’2020论文<sup>[1]</sup>。</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/motiv.jpg\" alt data-zoomable></p></div>\n<p>上图显示了一个来自真实用电记录的具体示例，它可以更好地解释我们的动机：图a显示了窃电用户在一年中的用电情况：1月到5月是没被抓时的用电曲线，之后是被抓后正常的用电情况。我们给每个月分配了最有代表性的shapelet，并在图b中显示了两个有意思的shapelet（＃72和＃67），以及它们的时间意识因素，其中深色区域表示shapelet相对于浅色区域更具区分性。shapelet演变图如图c所示，说明了shapelet在正常情况下如何从一个转移到另一个：对于正常的用电量记录，其shapelet的过渡有一条清晰的路径（＃90→＃67→＃ 85）。但是，对于异常数据，他们走一条不明显的路径（＃85→＃72→＃7），这表明shapelet转移路径的连通性可以为检测异常时间序列提供了参考标准。最后，我们将学习到的shapelet和时间序列表示的问题转化为图嵌入问题，并用图算法进行解决。</p>\n<h4 id=\"捕捉具有时间意识的Shapelet\">捕捉具有时间意识的Shapelet<a href=\"post/time2graph#捕捉具有时间意识的Shapelet\"></a></h4><p>正式地，一个shaplet <img src=\"https://vachelhu.github.io/source/img/blog/t2g/v.png\">是代表某个类别的时序片段。更确切地说，它可以通过某些特定的指标，将时序<img src=\"https://vachelhu.github.io/source/img/blog/t2g/T.png\">分成两个较小的集合，一个接近<img src=\"https://vachelhu.github.io/source/img/blog/t2g/v.png\">而另一个远离，例如对于时间序列分类任务，可以将正样本和负样本放入不同的组中，具体可以形式化为</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq1.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>这里<img src=\"https://vachelhu.github.io/source/img/blog/t2g/S().png\">表示相对于特定组<img src=\"https://vachelhu.github.io/source/img/blog/t2g/T*.png\">的距离，函数<img src=\"https://vachelhu.github.io/source/img/blog/t2g/g.png\">接受两个有限集作为输入，返回一个标量值以指示这两个集合有多远，它可以是信息增益或集合上的一些不相似性度量，即KL散度。 </p>\n<p>为了捕获Shapelet 的动态性，我们定义了两个因素来定量测量Shapelet在不同水平上的时序影响。具体来说，我们介绍一个<strong>局部因素</strong><img src=\"https://vachelhu.github.io/source/img/blog/t2g/wn.png\">来表示特定Shapelet的第n个元素的内部重要性。之后，Shapelet <img src=\"https://vachelhu.github.io/source/img/blog/t2g/v.png\">与时序片段<img src=\"https://vachelhu.github.io/source/img/blog/t2g/s.png\">之间的距离可以被重新定义为</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq2.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>这里<img src=\"https://vachelhu.github.io/source/img/blog/t2g/a*.png\">指的是DTW距离的最佳对齐。另一方面，在<strong>全局范围</strong>内，我们旨在衡量跨段的时间效应对shapelet的判别力的影响。直觉上Shapelet在不同的时间步长可能代表完全不同的含义，我们可以直接通过添加段级权重来测量此类偏差。正式地，我们设定了一个全局因素<img src=\"https://vachelhu.github.io/source/img/blog/t2g/um.png\">捕获跨段影响，然后Shapelet <img src=\"https://vachelhu.github.io/source/img/blog/t2g/v.png\">与时序<img src=\"https://vachelhu.github.io/source/img/blog/t2g/t_.png\">之间的距离可以写为</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq3.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>然后给定一个分类任务，我们可以建立一套监督学习方法，以选择最重要的具有时间意识的Shapelet，并可以为每一个shapelet学习其相应的时间因素<img src=\"https://vachelhu.github.io/source/img/blog/t2g/wi.png\">和<img src=\"https://vachelhu.github.io/source/img/blog/t2g/ui.png\">。特别地，我们有一个从所有子序列中选择出的作为shapelet候选者的片段池，以及一组带标签的时间序列 <img src=\"https://vachelhu.github.io/source/img/blog/t2g/T.png\">。对于每个候选者<img src=\"https://vachelhu.github.io/source/img/blog/t2g/v.png\">，我们都有以下目标函数：</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq4.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>在分别从Shapelet候选者那里学习了时序因素之后，我们选择损失最小的前K个shapelet作为最终的具有时间意识的shapelet。</p>\n<h4 id=\"构建Shapelet演化图\">构建Shapelet演化图<a href=\"post/time2graph#构建Shapelet演化图\"></a></h4><p><strong>Shapelet 演化图</strong>是有向加权图<img src=\"https://vachelhu.github.io/source/img/blog/t2g/gve.png\">，其中<img src=\"https://vachelhu.github.io/source/img/blog/t2g/v_.png\">由K个顶点所组成，每个顶点表示一个shapelet，每个有向边<img src=\"https://vachelhu.github.io/source/img/blog/t2g/eine.png\">  与其权重<img src=\"https://vachelhu.github.io/source/img/blog/t2g/wij.png\">，表示在相同的时间序列中，shapelet <img src=\"https://vachelhu.github.io/source/img/blog/t2g/vinv.png\">跟着另一个shapelet<img src=\"https://vachelhu.github.io/source/img/blog/t2g/vjinv.png\"> 的出现概率。这里的关键思想是，图中的路径可以自然反映出shapelet的演变及其过渡模式，然后可以将图嵌入算法应用于学习shapelet以及时间序列表示。 </p>\n<p>我们首先分配每个时序片段<img src=\"https://vachelhu.github.io/source/img/blog/t2g/si.png\">到距离最近的几个Shapelets。详细地说，我们将shapelet的赋值概率标准化为</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq5.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>这里有</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/eq6.png\" style=\"border:none;\" data-zoomable></p></div>\n<p>的预定义约束，<img src=\"https://vachelhu.github.io/source/img/blog/t2g/ddelta.png\">。然后，对于每个对<img src=\"https://vachelhu.github.io/source/img/blog/t2g/jk.png\">，我们从shapelet创建加权边<img src=\"https://vachelhu.github.io/source/img/blog/t2g/vij.png\">到<img src=\"https://vachelhu.github.io/source/img/blog/t2g/vik.png\">，并通过权重<img src=\"https://vachelhu.github.io/source/img/blog/t2g/p*p.png\">合并所有的重复边。最后，我们将从每个节点获得的边缘权重归一化为1，这自然会解释每对节点之间的边缘权重。</p>\n<h4 id=\"时序表示学习\">时序表示学习<a href=\"post/time2graph#时序表示学习\"></a></h4><p>最后，我们对如上构造的shapelet演化图来学习Shaplet和给定时间序列的表示。我们首先采用现有的图形嵌入算法DeepWalk<sup>[10]</sup>来获得顶点（shapelet）的表示向量，然后对于在时间序列中的每个片段，我们分配其到不同的shapelet及其权重。最后连接或聚合所有这些嵌入向量以获得原始时间序列的表示向量。然后可以将时间序列嵌入应用于各种下行任务，请参考本文的实验部分<sup>[1]</sup>。</p>\n<h4 id=\"评价结果\">评价结果<a href=\"post/time2graph#评价结果\"></a></h4><p>我们对来自UCR-Archive <sup>[11]</sup>的三个公共基准数据集，和来自中国国家电网和中国电信的两个真实世界数据集进行时间序列分类任务。实验结果如下表所示：</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/exp.jpg\" alt data-zoomable></p></div>\n<p>我们还进行了广泛的消融实验和观察研究，以验证我们提出的框架。在这里，我们在不同的时间步上构建了Shapelet演化图，以更深入地了解shapelet动态演变，如下图所示。它显示了两个图表，一个表示一月，另一个表示七月。在1月，shapelet＃45具有较大的输入/输出度，并且在1月和2月（深色区域）突出显示了其对应的时间意识分数。这表明45号shapelet很可能在年初开始成为一种常见模式。至于7月份，shapelet＃45不再像1月份那样重要。同时，shapelet＃42（在1月几乎是一个孤立点）在7月变得非常重要。尽管在构造shapelet演化图时我们没有明确考虑季节性信息，但包含的时机因素意味着它们已被纳入图生成过程中。</p>\n<div class=\"article-img\"><p><img src=\"https://vachelhu.github.io/source/img/blog/t2g/vis.jpg\" alt data-zoomable></p></div>\n<h3 id=\"Reference\">Reference<a href=\"post/time2graph#Reference\"></a></h3><p>[1] Cheng, Z; Yang, Y; Wang, W; Hu, W; Zhuang, Y and Song, G, 2020, Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets, In AAAI, 2020</p>\n<p>[2] Peng, X.; Huang, J.; Hu, Q.; Zhang, S.; and Metaxas, D. N. 2014. Head pose estimation by instance parameterization. In <em>ICPR’14</em>, 1800–1805.</p>\n<p>[3] Shimodaira, H.; Noma, K.-i.; Nakai, M.; and Sagayama, S. 2002. Dynamic time-alignment kernel in support vector machine. In <em>NIPS’02</em>, 921–928.</p>\n<p>[4] Malhotra, P.; Ramakrishnan, A.; Anand, G.; Vig, L.; Agar- wal, P.; and Shroff, G. 2016. Lstm-based encoder- decoder for multi-sensor anomaly detection. <em>arXiv preprint arXiv:1607.00148</em>.</p>\n<p>[5] Johnson, M.; Duvenaud, D. K.; Wiltschko, A.; Adams, R. P.; and Datta, S. R. 2016. Composing graphical models with neu- ral networks for structured representations and fast inference. In <em>NIPS’16</em>, 2946–2954.</p>\n<p>[6] Ye, L., and Keogh, E. 2011. Time series shapelets: a novel technique that allows accurate, interpretable and fast classifi- cation. <em>DMKD.</em> 22(1):149–182.</p>\n<p>[7] Bostrom, A., and Bagnall, A. 2017. Binary shapelet trans- form for multiclass time series classification. In <em>TLSD- KCS’17.</em> 24–46.</p>\n<p>[8] Hills, J.; Lines, J.; Baranauskas, E.; Mapp, J.; and Bagnall, A. 2014. Classification of time series by shapelet transformation. <em>DMKD.</em> 28(4):851–881</p>\n<p>[9] Lines, J.; Davis, L. M.; Hills, J.; and Bagnall, A. 2012. A shapelet transform for time series classification. In <em>KDD’12</em>, 289–297.</p>\n<p>[10] Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk: Online learning of social representations. In <em>KDD</em>, 701–710.</p>\n<p>[11] Dau, H. A.; Keogh, E.; Kamgar, K.; Yeh, C.-C. M.; Zhu, Y.; Gharghabi, S.; Ratanamahatana, C. A.; Yanping; Hu, B.; Begum, N.; Bagnall, A.; Mueen, A.; and Batista, G. 2018. The ucr time series classification archive. <a href=\"https://www.cs.ucr.edu/~eamonn/time_series_data_2018/\" target=\"_blank\" rel=\"noopener\">https://www.cs.ucr.edu/~eamonn/time_series_data_2018/</a>.</p>\n","prev":{"title":"2019年度总结","slug":"summary_2019"},"next":{"title":"2019春招小记","slug":"interview"},"link":"https://vachelhu.github.io/blog/post/time2graph/","toc":[{"title":"模型：时序到图","id":"模型：时序到图","index":"1"}],"copyright":{"author":"Wenjie Hu","link":"<a href=\"https://vachelhu.github.io/blog/post/time2graph/\" title=\"Time2Graph\">https://vachelhu.github.io/blog/post/time2graph/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}