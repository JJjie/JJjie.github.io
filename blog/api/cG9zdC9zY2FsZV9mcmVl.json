{"title":"Representation learning for scale-free networks","date":"2018-01-10T03:23:38.000Z","slug":"scale_free","comments":true,"tags":["科研"],"categories":["技术"],"updated":"2020-01-29T02:43:41.222Z","content":"<h1 id=\"无尺度图的表示学习\">无尺度图的表示学习<a href=\"post/scale_free#无尺度图的表示学习\"></a></h1><p>最近我们提出设计一种网络嵌入算法的度惩罚原则，以有效保留无标度特性，该研究成果被人工智能顶会AAAI录用，并被著名自媒体<code>机器之心</code>报道。本文转载<a href=\"https://www.jiqizhixin.com/articles/2018-01-02-5\" target=\"_blank\" rel=\"noopener\">机器之心的报道</a>，对我们的工作做更详细的阐述。</p>\n<p>由于网络能够编码丰富而复杂的数据（如人际关系和互动），网络分析（network analysis）已经在人工智能的许多领域吸引了大量的研究工作。网络分析的一个主要挑战是如何正确表示网络，以保留网络的结构特性。最直接的方法是用邻接矩阵（adjacency matrix）表示网络。但邻接矩阵会受到数据稀疏性的影响。其它传统的网络表征依赖于人工设计的网络特征（例如聚类系数），不够灵活、不可扩展，并且需要艰苦的人力。</p>\n<p>因此我们想尝试研究如下问题：如何学习并保留无标度（scale-free）特性的网络嵌入（Network Embedding）。作为一个网络的表征，顶点（vertex）嵌入向量被认为可以很好地重构网络。现存的多数算法都是在欧氏空间学习网络嵌入。然而，我们发现大多数传统的网络嵌入算法会对高度（high degree）顶点的数量估计过高。图 1（b）给出了一个例子，其表征由拉普拉斯特征映射（Laplacian Eigenmap）学习得到。我们尝试从理论上分析和理解这一点，并研究通过把我们的问题转化为高维球体填充问题（Sphere-Packing Problem），在欧氏空间中恢复幂律分布（power-law distributed）顶点度的可行性。通过分析，我们发现从理论上，适度增加嵌入向量的维度有助于保留无标度特性。详见第 2 部分。</p>\n<div class=\"article-img\"><p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/ef9e590a-5430-422e-8689-e7b7e0730138/48311%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-27%20%E4%B8%8B%E5%8D%882.57.05.png\" style=\"zoom:67%;\" data-zoomable></p></div>\n<p><em><small>图 1：真实网络的无标度特性。（a）是一个学术网络的度分布。（b）和（c）分别是基于拉普拉斯特征映射（LE）和我们提出的方法（DPWalker）学习的顶点表征重构的网络的度分布。</small></em></p>\n<div class=\"article-img\"><p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/ef9e590a-5430-422e-8689-e7b7e0730138/79266%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-27%20%E4%B8%8B%E5%8D%882.58.02.png\" alt data-zoomable></p></div>\n<p><em><small>图 2：从左到右：一个以集线器顶点为中心的自我中心网络（ego-network），一个可能的嵌入解决方案（等价于一个高维球填充解决方案），但导致重构失败，其中高度顶点的数目被估计过高。</small></em></p>\n<p>为了验证方法的有效性，我们在第四部分中对合成数据和五组真实数据集进行了实验。实验结果表明，我们的方法不仅能够保留网络的无标度特性，而且在不同的网络分析任务中优于最先进的嵌入算法。论文的贡献总结如下：</p>\n<ul>\n<li>我们通过将问题转化为高维球体填充问题，分析了在欧氏空间中基于学习到的顶点表征来重构无标度网络的难度和可行性。</li>\n<li>我们提出度惩罚（degree penalty）原则和两个实现来保留网络的无标度特性，并提高顶点表征的有效性。</li>\n<li>我们通过进行大量实验来验证我们提出的原则，并发现与几个最先进的基线算法相比，我们的方法在 6 个数据集和 3 个任务上有显著提升。</li>\n</ul>\n<div class=\"article-img\"><p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/ef9e590a-5430-422e-8689-e7b7e0730138/27069%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-27%20%E4%B8%8B%E5%8D%882.59.32.png\" alt data-zoomable></p></div>\n<p><em><small>图 3：模型参数分析。（a）和（b）分别展示了合成数据集和 Facebook 数据集中嵌入维度 k 的敏感性。（c）和（d）表示度惩罚参数 β 的敏感性。由于空间限制，我们忽略了其它数据集上的结果。</small></em></p>\n<div class=\"article-img\"><p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/ef9e590a-5430-422e-8689-e7b7e0730138/46980%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-27%20%E4%B8%8B%E5%8D%883.00.01.png\" style=\"zoom:48%;\" data-zoomable><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/ef9e590a-5430-422e-8689-e7b7e0730138/98632%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-27%20%E4%B8%8B%E5%8D%883.00.41.png\" style=\"zoom:48%;\" data-zoomable></p></div>\n<p><em><small>表 1：不同方法在无标度特性重构中的表现。对于每种方法，选择使 Pearson 系数最大化的 ε。</small></em></p>\n<p><em><small>表 2：连接（link）预测的实验结果。</small></em></p>\n<p>论文链接：<a href=\"https://arxiv.org/abs/1711.10755\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1711.10755</a></p>\n","prev":{"title":"《六顶思考帽》读书笔记","slug":"sixhat"},"next":{"title":"背包问题——“完全背包”详解及实现","slug":"beibaowenti"},"link":"https://vachelhu.github.io/blog/post/scale_free/","toc":[{"title":"无尺度图的表示学习","id":"无尺度图的表示学习","index":"1"}],"copyright":{"author":"Wenjie Hu","link":"<a href=\"https://vachelhu.github.io/blog/post/scale_free/\" title=\"Representation learning for scale-free networks\">https://vachelhu.github.io/blog/post/scale_free/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}